---
phase: 03-icp-qualification-leads-agent
plan: 02
type: execute
wave: 2
depends_on: [03-01]
files_modified:
  - src/lib/icp/crawl-cache.ts
  - src/lib/icp/scorer.ts
  - src/lib/verification/leadmagic.ts
autonomous: true
requirements: [AI-04, ENRICH-05]

must_haves:
  truths:
    - "Calling getCrawlMarkdown(domain) returns cached markdown if Company.crawledAt exists, otherwise scrapes via Firecrawl and caches the result"
    - "Calling scorePersonIcp(personId, workspaceSlug) returns a 0-100 score with reasoning and confidence, using the workspace ICP criteria prompt"
    - "Calling verifyEmail(email) returns a status (valid/invalid/catch_all/unknown) and an isExportable boolean (true only for 'valid')"
    - "ICP score is persisted on PersonWorkspace (workspace-scoped), not on Person (workspace-agnostic)"
    - "Email verification result is persisted in Person.enrichmentData JSON as emailVerificationStatus + emailVerifiedAt"
    - "Verification cost is tracked via incrementDailySpend with 'leadmagic-verify' provider"
  artifacts:
    - path: "src/lib/icp/crawl-cache.ts"
      provides: "Homepage crawl caching (Firecrawl scrape + Company record storage)"
      exports: ["getCrawlMarkdown"]
    - path: "src/lib/icp/scorer.ts"
      provides: "ICP scoring via Claude Haiku generateObject"
      exports: ["scorePersonIcp", "IcpScoreResult"]
    - path: "src/lib/verification/leadmagic.ts"
      provides: "LeadMagic email verification adapter + export gate"
      exports: ["verifyEmail", "VerificationResult"]
  key_links:
    - from: "src/lib/icp/crawl-cache.ts"
      to: "src/lib/firecrawl/client.ts"
      via: "scrapeUrl() import"
      pattern: "scrapeUrl"
    - from: "src/lib/icp/crawl-cache.ts"
      to: "prisma.company"
      via: "findUnique + update for crawlMarkdown/crawledAt"
      pattern: "prisma\\.company\\.(findUnique|update|upsert)"
    - from: "src/lib/icp/scorer.ts"
      to: "src/lib/icp/crawl-cache.ts"
      via: "getCrawlMarkdown import"
      pattern: "getCrawlMarkdown"
    - from: "src/lib/icp/scorer.ts"
      to: "ai + @ai-sdk/anthropic"
      via: "generateObject with Claude Haiku"
      pattern: "generateObject"
    - from: "src/lib/verification/leadmagic.ts"
      to: "src/lib/enrichment/costs.ts"
      via: "incrementDailySpend import"
      pattern: "incrementDailySpend"
---

<objective>
Build the ICP scoring engine (crawl cache + Haiku classifier) and the LeadMagic email verification adapter.

Purpose: These are the two core business logic modules that Phase 3 MCP tools will call. ICP scoring (AI-04) enables prospect qualification against workspace-specific criteria. Email verification (ENRICH-05) gates exports to prevent unverified emails from reaching EmailBison.

Output: Three library modules — `crawl-cache.ts`, `scorer.ts`, `leadmagic.ts` — ready to be wired into MCP tools in Plan 03-03.
</objective>

<execution_context>
@/Users/jjay/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jjay/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-icp-qualification-leads-agent/03-CONTEXT.md
@.planning/phases/03-icp-qualification-leads-agent/03-RESEARCH.md
@.planning/phases/03-icp-qualification-leads-agent/03-01-SUMMARY.md

<interfaces>
<!-- Key types and contracts the executor needs. Extracted from codebase. -->

From src/lib/firecrawl/client.ts:
```typescript
export interface ScrapeResult {
  url: string;
  markdown: string;
  title?: string;
  metadata?: Record<string, unknown>;
}

export async function scrapeUrl(url: string): Promise<ScrapeResult>;
```

From src/lib/enrichment/costs.ts:
```typescript
export const PROVIDER_COSTS: Record<string, number>;  // includes "leadmagic-verify": 0.05
export async function incrementDailySpend(provider: string, costUsd: number): Promise<void>;
```

From src/lib/enrichment/log.ts:
```typescript
export async function recordEnrichment(params: {
  entityId: string;
  entityType: EntityType;
  provider: Provider;
  status: EnrichmentStatus;
  fieldsWritten?: string[];
  costUsd?: number;
  rawResponse?: unknown;
  errorMessage?: string;
  workspaceSlug?: string;
}): Promise<void>;
```

From src/lib/normalizer/industry.ts (pattern to follow for generateObject):
```typescript
import { generateObject } from "ai";
import { anthropic } from "@ai-sdk/anthropic";
import { z } from "zod";

const IndustrySchema = z.object({
  canonical: z.enum(CANONICAL_VERTICALS as unknown as [string, ...string[]]),
  confidence: z.enum(["high", "medium", "low"]),
});

// Uses: const { object } = await generateObject({ model: anthropic("claude-haiku-4-5-20251001"), schema, prompt });
```

Prisma schema additions from Plan 03-01:
```prisma
// Company
crawlMarkdown  String?
crawledAt      DateTime?

// PersonWorkspace
icpScore       Int?
icpReasoning   String?
icpConfidence  String?
icpScoredAt    DateTime?

// Workspace
icpCriteriaPrompt    String?
normalizationPrompt  String?
outreachTonePrompt   String?
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Crawl cache + ICP scorer</name>
  <files>
    src/lib/icp/crawl-cache.ts
    src/lib/icp/scorer.ts
  </files>
  <action>
**1. Create `src/lib/icp/crawl-cache.ts`:**

```typescript
/**
 * Crawl cache — caches Firecrawl homepage scrapes on the Company record.
 * Checks Company.crawledAt before calling Firecrawl. Cache is permanent
 * (no TTL) — use force_recrawl parameter to refresh.
 */
```

Export `getCrawlMarkdown(domain: string, forceRecrawl?: boolean): Promise<string | null>`:

- Look up `prisma.company.findUnique({ where: { domain } })`
- If `company.crawledAt` is not null AND `forceRecrawl` is not true, return `company.crawlMarkdown` (cache hit)
- Otherwise, call `scrapeUrl(`https://${domain}`)` from `@/lib/firecrawl/client`
- If the company record does NOT exist, upsert it: `prisma.company.upsert({ where: { domain }, create: { domain, name: domain, crawlMarkdown: result.markdown, crawledAt: new Date() }, update: { crawlMarkdown: result.markdown, crawledAt: new Date() } })` — This handles Pitfall 4 from research (Company record may not exist yet)
- If the company record exists, update it with `crawlMarkdown` and `crawledAt`
- Return the markdown string (truncated to 50,000 chars to avoid DB bloat — homepage markdown can be large)
- Wrap the Firecrawl call in try/catch. On error, log via `console.error` (safe — this runs in MCP server context) and return null

**2. Create `src/lib/icp/scorer.ts`:**

```typescript
/**
 * ICP scorer — qualifies a person against workspace ICP criteria.
 * Uses Firecrawl homepage scrape + enrichment data + Claude Haiku to produce
 * a 0-100 score with reasoning and confidence level.
 *
 * Score is stored on PersonWorkspace (not Person) because ICP fit is
 * workspace-specific — Pitfall 5 from research.
 */
```

Define and export `IcpScoreResult`:
```typescript
export interface IcpScoreResult {
  score: number;       // 0-100
  reasoning: string;   // 1-3 sentences
  confidence: "high" | "medium" | "low";
}
```

Define Zod schema for `generateObject`:
```typescript
const IcpScoreSchema = z.object({
  score: z.number().min(0).max(100),
  reasoning: z.string().describe("1-3 sentence explanation of ICP fit"),
  confidence: z.enum(["high", "medium", "low"]).describe("Data completeness: high=all signals, medium=2/3, low=sparse"),
});
```

Export `scorePersonIcp(personId: string, workspaceSlug: string, forceRecrawl?: boolean): Promise<IcpScoreResult>`:

1. Fetch the person: `prisma.person.findUniqueOrThrow({ where: { id: personId }, include: { workspaces: { where: { workspace: workspaceSlug } } } })`
2. Fetch the workspace: `prisma.workspace.findUniqueOrThrow({ where: { slug: workspaceSlug } })` — needed for `icpCriteriaPrompt`
3. If `workspace.icpCriteriaPrompt` is null or empty, throw an error: "No ICP criteria prompt configured for workspace '{workspaceSlug}'. Use set_workspace_prompt to configure it first."
4. Get company markdown: `const websiteMarkdown = person.companyDomain ? await getCrawlMarkdown(person.companyDomain, forceRecrawl) : null`
5. Fetch company record if exists (for headcount, industry): `const company = person.companyDomain ? await prisma.company.findUnique({ where: { domain: person.companyDomain } }) : null`
6. Build the scoring prompt (helper function `buildScoringPrompt`):
   - Include person data: name, jobTitle, company, vertical, location
   - Include company data: headcount, industry, description, yearFounded (if company record exists)
   - Include website markdown (first 3000 chars, or note "No website data available" if null)
   - Parse person.enrichmentData JSON for seniority level if present
7. Call `generateObject({ model: anthropic("claude-haiku-4-5-20251001"), schema: IcpScoreSchema, system: workspace.icpCriteriaPrompt, prompt: scoringPrompt })`
8. Persist the result: `prisma.personWorkspace.update({ where: { personId_workspace: { personId, workspace: workspaceSlug } }, data: { icpScore: object.score, icpReasoning: object.reasoning, icpConfidence: object.confidence, icpScoredAt: new Date() } })`
   - Note: Use the `@@unique` composite key `[personId, workspace]` for the where clause. The actual unique constraint map name is `LeadWorkspace_leadId_workspace_key`, but Prisma uses the model field names for the compound unique identifier.
9. Return the IcpScoreResult object

The `buildScoringPrompt` helper should produce something like:
```
Score this prospect's ICP fit from 0-100 based on the workspace ICP criteria provided in the system prompt.

## Person Data
- Name: {firstName} {lastName}
- Job Title: {jobTitle ?? "Unknown"}
- Company: {company ?? "Unknown"}
- Industry: {vertical ?? "Unknown"}
- Location: {location ?? "Unknown"}
- Seniority: {seniority from enrichmentData ?? "Unknown"}

## Company Data
- Headcount: {headcount ?? "Unknown"}
- Industry: {company.industry ?? "Unknown"}
- Description: {company.description ?? "Unknown"}
- Year Founded: {company.yearFounded ?? "Unknown"}

## Company Website (homepage excerpt)
{websiteMarkdown?.slice(0, 3000) ?? "No website data available — score based on available data only."}

Return a score from 0-100 and 1-3 sentence reasoning. Set confidence based on data completeness:
- "high": Person data + company data + website all available
- "medium": 2 out of 3 signal types available
- "low": Only 1 signal type or very sparse data
```

Wrap the entire function in try/catch. On AI error, re-throw with a descriptive message. On Prisma error, re-throw.
  </action>
  <verify>
    <automated>cd /Users/jjay/programs/outsignal-agents && npx tsc --noEmit src/lib/icp/crawl-cache.ts src/lib/icp/scorer.ts 2>&1 | head -20</automated>
  </verify>
  <done>
    - `getCrawlMarkdown` reads from Company.crawlMarkdown cache, falls back to Firecrawl scrapeUrl, and upserts the Company record
    - `scorePersonIcp` fetches person + workspace + company data, builds prompt, calls generateObject with Haiku, persists score on PersonWorkspace
    - ICP score is stored on PersonWorkspace (workspace-scoped), not Person
    - Missing ICP criteria prompt throws a clear error message
    - TypeScript compiles without errors
  </done>
</task>

<task type="auto">
  <name>Task 2: LeadMagic email verification adapter</name>
  <files>
    src/lib/verification/leadmagic.ts
  </files>
  <action>
**Create `src/lib/verification/leadmagic.ts`:**

```typescript
/**
 * LeadMagic email verification adapter.
 * Verifies email deliverability via LeadMagic API.
 *
 * Endpoint: POST https://api.leadmagic.io/v1/people/email-validation
 * Auth: X-API-Key header (same LEADMAGIC_API_KEY as email-finding adapter)
 *
 * Status values: valid | invalid | valid_catch_all | catch_all | unknown
 * Export policy: STRICT — only "valid" emails are exportable.
 * Cost: $0.05 for valid/invalid/valid_catch_all; FREE for catch_all/unknown.
 *
 * IMPORTANT: catch_all and valid_catch_all are BOTH blocked from export.
 * "valid_catch_all" sounds safe because "valid" is in the name, but the
 * domain accepts ALL emails — deliverability is unverifiable.
 */
```

Define and export:
```typescript
export interface VerificationResult {
  email: string;
  status: "valid" | "invalid" | "valid_catch_all" | "catch_all" | "unknown";
  isExportable: boolean;  // true ONLY for "valid"
  costUsd: number;
}
```

Define the Zod response schema:
```typescript
const VerifyResponseSchema = z.object({
  email_status: z.enum(["valid", "invalid", "valid_catch_all", "catch_all", "unknown"]),
  email: z.string().optional(),
  credits_consumed: z.number().optional(),
});
```

Cost lookup (per research):
```typescript
const VERIFICATION_COST: Record<string, number> = {
  valid: 0.05,
  invalid: 0.05,
  valid_catch_all: 0.05,
  catch_all: 0,
  unknown: 0,
};
```

Export `verifyEmail(email: string): Promise<VerificationResult>`:

1. Get API key from `process.env.LEADMAGIC_API_KEY` (reuse same env var as email-finding adapter — same LeadMagic account)
2. POST to `https://api.leadmagic.io/v1/people/email-validation` with `{ email }` body, `X-API-Key` header, `Content-Type: application/json`
3. Use a 10-second timeout (AbortController pattern, same as existing leadmagic adapter)
4. Handle HTTP errors:
   - 429: throw with `(err as any).status = 429` (enables waterfall retry/backoff)
   - 404/422: throw permanent error
   - Other: throw generic error
5. Parse response with `VerifyResponseSchema.safeParse(raw)`. On parse failure, log raw response via `console.error` and return `{ email, status: "unknown", isExportable: false, costUsd: 0 }` (fail-safe: unknown = not exportable)
6. Track cost via `incrementDailySpend("leadmagic-verify", costUsd)` — only when `costUsd > 0`
7. Record enrichment provenance via `recordEnrichment({ entityId: personId (will need to accept as param OR look up by email), entityType: "person", provider: "leadmagic-verify", status: "success", costUsd, rawResponse: raw })`

**DECISION: Accept `personId` as an optional second parameter** for enrichment logging. When called from the MCP export tool, personId will be available. When called standalone, skip enrichment logging.

Updated signature: `verifyEmail(email: string, personId?: string): Promise<VerificationResult>`

8. Persist verification result on the Person record (if personId provided):
```typescript
if (personId) {
  const person = await prisma.person.findUnique({ where: { id: personId } });
  const existing = person?.enrichmentData ? JSON.parse(person.enrichmentData) : {};
  await prisma.person.update({
    where: { id: personId },
    data: {
      enrichmentData: JSON.stringify({
        ...existing,
        emailVerificationStatus: result.status,
        emailVerifiedAt: new Date().toISOString(),
      }),
    },
  });
}
```

9. Return `{ email, status: parsed.data.email_status, isExportable: parsed.data.email_status === "valid", costUsd }`

Also export a helper for the export gate:
```typescript
/**
 * Check if a person's email is verified and exportable.
 * Returns cached verification status if available, null if never verified.
 */
export async function getVerificationStatus(personId: string): Promise<{ status: string; isExportable: boolean } | null> {
  const person = await prisma.person.findUnique({ where: { id: personId } });
  if (!person?.enrichmentData) return null;
  const data = JSON.parse(person.enrichmentData);
  if (!data.emailVerificationStatus) return null;
  return {
    status: data.emailVerificationStatus,
    isExportable: data.emailVerificationStatus === "valid",
  };
}
```
  </action>
  <verify>
    <automated>cd /Users/jjay/programs/outsignal-agents && npx tsc --noEmit src/lib/verification/leadmagic.ts 2>&1 | head -20</automated>
  </verify>
  <done>
    - `verifyEmail(email, personId?)` calls LeadMagic verification endpoint, returns VerificationResult with isExportable boolean
    - Only "valid" status maps to isExportable=true (strict policy)
    - Cost tracked via incrementDailySpend with "leadmagic-verify" provider
    - Verification result persisted in Person.enrichmentData JSON
    - `getVerificationStatus(personId)` reads cached result from Person.enrichmentData
    - TypeScript compiles without errors
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes for all three new files
2. `getCrawlMarkdown` function exists and exports from `src/lib/icp/crawl-cache.ts`
3. `scorePersonIcp` function exists and exports from `src/lib/icp/scorer.ts`
4. `verifyEmail` and `getVerificationStatus` export from `src/lib/verification/leadmagic.ts`
5. ICP score writes to PersonWorkspace (not Person) — verify by grepping for `prisma.personWorkspace.update` in scorer.ts
6. No `console.log` calls (only `console.error` for logging)
</verification>

<success_criteria>
- Three library modules compile and export their public APIs
- ICP scorer uses workspace-scoped icpCriteriaPrompt for scoring
- ICP score persisted on PersonWorkspace (workspace-specific, not Person)
- Email verification follows strict policy (only "valid" is exportable)
- Crawl cache prevents redundant Firecrawl API calls
- Cost tracking uses distinct "leadmagic-verify" provider
</success_criteria>

<output>
After completion, create `.planning/phases/03-icp-qualification-leads-agent/03-02-SUMMARY.md`
</output>
