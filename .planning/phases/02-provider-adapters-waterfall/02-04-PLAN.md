---
phase: 02-provider-adapters-waterfall
plan: 04
type: execute
wave: 3
depends_on: ["02-01", "02-02", "02-03"]
files_modified:
  - src/lib/enrichment/waterfall.ts
  - src/lib/enrichment/queue.ts
  - src/app/api/enrichment/jobs/process/route.ts
  - src/app/api/enrichment/run/route.ts
autonomous: true
requirements: [ENRICH-02, ENRICH-03, ENRICH-04]

must_haves:
  truths:
    - "enrichEmail(personId) tries Prospeo, then LeadMagic, then FindyMail in order, stopping at first email found"
    - "enrichCompany(domain) tries AI Ark first, falls back to Firecrawl if AI Ark returns no data"
    - "Circuit breaker skips a provider after 5 consecutive failures within a batch"
    - "Rate-limited calls (429) retry with exponential backoff (1s, 2s, 4s) up to 3 attempts"
    - "Daily cap hit pauses the job with resumeAt set to midnight UTC tomorrow"
    - "Queue processor (processNextChunk) picks up pending and resume-eligible paused jobs"
    - "AI normalizers run inline after provider data is written to person/company records"
    - "When a person has no LinkedIn URL, Prospeo tries name+company fallback, and if that fails the waterfall is skipped"
  artifacts:
    - path: "src/lib/enrichment/waterfall.ts"
      provides: "enrichEmail(), enrichCompany() waterfall orchestrators"
      exports: ["enrichEmail", "enrichCompany"]
    - path: "src/lib/enrichment/queue.ts"
      provides: "Updated processNextChunk with paused status handling"
      exports: ["enqueueJob", "processNextChunk"]
    - path: "src/app/api/enrichment/jobs/process/route.ts"
      provides: "Wired POST handler that calls waterfall via onProcess callback"
      exports: ["POST"]
    - path: "src/app/api/enrichment/run/route.ts"
      provides: "POST trigger to enqueue batch enrichment jobs"
      exports: ["POST"]
  key_links:
    - from: "src/lib/enrichment/waterfall.ts"
      to: "src/lib/enrichment/providers/*"
      via: "imports and calls adapters sequentially"
      pattern: "import.*from.*providers"
    - from: "src/lib/enrichment/waterfall.ts"
      to: "src/lib/enrichment/costs.ts"
      via: "checkDailyCap before each provider call, incrementDailySpend after success"
      pattern: "(checkDailyCap|incrementDailySpend)"
    - from: "src/lib/enrichment/waterfall.ts"
      to: "src/lib/enrichment/merge.ts"
      via: "mergePersonData/mergeCompanyData to write provider results"
      pattern: "(mergePersonData|mergeCompanyData)"
    - from: "src/lib/enrichment/waterfall.ts"
      to: "src/lib/normalizer"
      via: "classifyIndustry, classifyJobTitle, classifyCompanyName after writes"
      pattern: "classify(Industry|JobTitle|CompanyName)"
    - from: "src/app/api/enrichment/jobs/process/route.ts"
      to: "src/lib/enrichment/waterfall.ts"
      via: "onProcess callback calls enrichEmail/enrichCompany"
      pattern: "enrich(Email|Company)"
---

<objective>
Wire the waterfall orchestration logic and integrate it with the existing job queue, creating the end-to-end enrichment pipeline.

Purpose: This is the critical integration plan — it connects all provider adapters into sequential waterfalls, handles circuit breaker, cost cap, retries, and data merge, then wires everything into the existing job queue so batch enrichment runs automatically.
Output: waterfall.ts with enrichEmail/enrichCompany, updated queue.ts with paused status, wired process route, and a new run trigger route.
</objective>

<execution_context>
@/Users/jjay/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jjay/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-provider-adapters-waterfall/02-RESEARCH.md
@.planning/phases/02-provider-adapters-waterfall/02-01-SUMMARY.md
@.planning/phases/02-provider-adapters-waterfall/02-02-SUMMARY.md
@.planning/phases/02-provider-adapters-waterfall/02-03-SUMMARY.md

@src/lib/enrichment/types.ts
@src/lib/enrichment/queue.ts
@src/lib/enrichment/dedup.ts
@src/lib/enrichment/log.ts
@src/lib/enrichment/costs.ts
@src/lib/enrichment/merge.ts
@src/lib/enrichment/providers/prospeo.ts
@src/lib/enrichment/providers/leadmagic.ts
@src/lib/enrichment/providers/findymail.ts
@src/lib/enrichment/providers/aiark.ts
@src/lib/enrichment/providers/firecrawl-company.ts
@src/lib/normalizer/index.ts
@src/app/api/enrichment/jobs/process/route.ts

<interfaces>
<!-- All types and functions available from prior plans -->

From src/lib/enrichment/types.ts:
```typescript
export type Provider = "prospeo" | "aiark" | "leadmagic" | "findymail" | "firecrawl" | "clay" | "ai-normalizer";
export type EntityType = "person" | "company";
export type EmailAdapter = (input: EmailAdapterInput) => Promise<EmailProviderResult>;
export type CompanyAdapter = (domain: string) => Promise<CompanyProviderResult>;
export interface EmailAdapterInput { linkedinUrl?: string; firstName?: string; lastName?: string; companyName?: string; companyDomain?: string; }
export interface EmailProviderResult { email: string | null; source: Provider; rawResponse: unknown; costUsd: number; /* + optional person fields */ }
export interface CompanyProviderResult { name?: string; industry?: string; headcount?: number; description?: string; website?: string; location?: string; yearFounded?: number; source: Provider; rawResponse: unknown; costUsd: number; }
```

From providers:
```typescript
export const prospeoAdapter: EmailAdapter;    // from providers/prospeo.ts
export const leadmagicAdapter: EmailAdapter;  // from providers/leadmagic.ts
export const findymailAdapter: EmailAdapter;  // from providers/findymail.ts
export const aiarkAdapter: CompanyAdapter;    // from providers/aiark.ts
export const firecrawlCompanyAdapter: CompanyAdapter; // from providers/firecrawl-company.ts
```

From src/lib/enrichment/dedup.ts:
```typescript
export async function shouldEnrich(entityId: string, entityType: EntityType, provider: Provider): Promise<boolean>;
```

From src/lib/enrichment/log.ts:
```typescript
export async function recordEnrichment(params: { entityId: string; entityType: EntityType; provider: Provider; status?: EnrichmentStatus; fieldsWritten?: string[]; costUsd?: number; rawResponse?: unknown; errorMessage?: string; }): Promise<void>;
```

From src/lib/enrichment/costs.ts:
```typescript
export const PROVIDER_COSTS: Record<string, number>;
export function todayUtc(): string;
export async function checkDailyCap(): Promise<boolean>;
export async function incrementDailySpend(provider: string, costUsd: number): Promise<void>;
```

From src/lib/enrichment/merge.ts:
```typescript
export async function mergePersonData(personId: string, data: Partial<{email, firstName, lastName, jobTitle, linkedinUrl, location, phone, company, companyDomain}>): Promise<string[]>;
export async function mergeCompanyData(domain: string, data: Partial<{name, industry, headcount, description, website, location, yearFounded, companyType}>): Promise<string[]>;
```

From src/lib/normalizer/index.ts:
```typescript
export function classifyIndustry(raw: string): Promise<{ vertical: string | null; confidence: number }>;
export function classifyCompanyName(raw: string): Promise<string>;
export function classifyJobTitle(raw: string): Promise<{ title: string; seniority: string | null }>;
```

From src/lib/enrichment/queue.ts:
```typescript
export async function enqueueJob(params: EnqueueJobParams): Promise<string>;
export async function processNextChunk(onProcess?: (entityId: string, job: { entityType: string; provider: string }) => Promise<void>): Promise<ChunkResult | null>;
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Waterfall orchestrators (enrichEmail + enrichCompany) with circuit breaker, retries, cost cap, and normalizers</name>
  <files>src/lib/enrichment/waterfall.ts</files>
  <action>
Create `src/lib/enrichment/waterfall.ts` with two main exports: `enrichEmail` and `enrichCompany`.

**Helper: CircuitBreaker type and sleep/backoff utilities**

```typescript
export interface CircuitBreaker {
  consecutiveFailures: Map<string, number>;
}

export function createCircuitBreaker(): CircuitBreaker {
  return { consecutiveFailures: new Map() };
}

function sleep(ms: number): Promise<void> {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

function exponentialBackoff(attempt: number): number {
  return Math.pow(2, attempt) * 1000; // 1s, 2s, 4s
}

const CIRCUIT_BREAKER_THRESHOLD = 5;
const MAX_RETRIES = 3;
```

**enrichEmail(personId, input, breaker, workspaceSlug?)**

Waterfall order: Prospeo -> LeadMagic -> FindyMail (per locked decision).

Logic:
1. Define `EMAIL_PROVIDERS` array of `{ adapter, name }` tuples:
   - `{ adapter: prospeoAdapter, name: "prospeo" as Provider }`
   - `{ adapter: leadmagicAdapter, name: "leadmagic" as Provider }`
   - `{ adapter: findymailAdapter, name: "findymail" as Provider }`

2. Special case — no LinkedIn URL handling (per locked decision):
   - If `!input.linkedinUrl`: Prospeo can still try name+company. Let Prospeo adapter handle it (it returns null if insufficient input). But if Prospeo returns null AND there's no LinkedIn URL, skip LeadMagic and FindyMail (they both need LinkedIn URL). So: only iterate Prospeo when no LinkedIn URL, not the full waterfall.

3. For each provider in the waterfall:
   a. **Circuit breaker check**: if `breaker.consecutiveFailures.get(name) >= CIRCUIT_BREAKER_THRESHOLD`, skip with console.warn
   b. **Dedup gate**: `await shouldEnrich(personId, "person", name)` — skip if false (already enriched by this provider)
   c. **Daily cap check**: `await checkDailyCap()` — if true, throw `new Error("DAILY_CAP_HIT")`
   d. **Call with retry loop** (max 3 attempts):
      - Try `adapter(input)`
      - On 429: `await sleep(exponentialBackoff(attempt))`, continue loop
      - On other error: break loop (permanent error)
   e. **On error** (after retries exhausted or permanent error):
      - `await recordEnrichment({ entityId: personId, entityType: "person", provider: name, status: "error", errorMessage, costUsd: 0, workspaceSlug })`
      - Note: recordEnrichment currently doesn't accept workspaceSlug — that's fine, add it if Plan 01 extended the log function, otherwise skip. The research says to add workspaceSlug to EnrichmentLog schema (Plan 01 does) but the log.ts function may not accept it yet. If log.ts doesn't have workspaceSlug param, add it to the recordEnrichment params interface and pass through to prisma.create.
      - Increment circuit breaker: `breaker.consecutiveFailures.set(name, (current ?? 0) + 1)`
      - Continue to next provider
   f. **On success** (result.email is non-null):
      - Write email to person via `mergePersonData(personId, { email: result.email, ...any additional person fields from result })`
      - `await incrementDailySpend(name, result.costUsd)`
      - `await recordEnrichment({ entityId: personId, entityType: "person", provider: name, status: "success", fieldsWritten, costUsd: result.costUsd, rawResponse: result.rawResponse })`
      - Reset circuit breaker: `breaker.consecutiveFailures.set(name, 0)`
      - **Run normalizers inline** after merge:
        - If person's `jobTitle` was just written (in fieldsWritten) or already exists: call `classifyJobTitle(jobTitle)` and update `jobTitle` and seniority (write seniority somewhere — for now store in enrichmentData JSON since Person model doesn't have a seniority column)
        - If person's `company` was written: call `classifyCompanyName(company)` and update
        - If person's `vertical` is null and company's `industry` is available: call `classifyIndustry(industry)` and set `vertical`
      - **Return** (stop waterfall — first email wins)
   g. If result.email is null: record as success with `fieldsWritten: []` (API was called but no email found), reset circuit breaker, continue to next provider

**enrichCompany(domain, breaker, workspaceSlug?)**

Waterfall order: AI Ark -> Firecrawl (per locked decision).

Logic:
1. Define `COMPANY_PROVIDERS` array:
   - `{ adapter: aiarkAdapter, name: "aiark" as Provider }`
   - `{ adapter: firecrawlCompanyAdapter, name: "firecrawl" as Provider }`

2. For each provider (same pattern as enrichEmail but for company data):
   a. Circuit breaker check
   b. Dedup gate: `shouldEnrich(domain, "company", name)` — NOTE: uses domain as entityId for companies (the Company model's unique identifier)
   c. Daily cap check
   d. Retry loop (same 429 backoff)
   e. On error: record, increment breaker, continue
   f. On success (any company field is non-null):
      - Check if company exists: `prisma.company.findUnique({ where: { domain } })`
      - If company doesn't exist, create a minimal record: `prisma.company.create({ data: { domain, name: result.name ?? domain } })`
      - Then `mergeCompanyData(domain, { name, industry, headcount, description, website, location, yearFounded })`
      - `incrementDailySpend`, `recordEnrichment`
      - **Run normalizers inline**:
        - If `industry` was written: `classifyIndustry(industry)` and update company's `industry` to canonical value
        - If `name` was written: `classifyCompanyName(name)` and update company's `name`
      - Reset circuit breaker
      - **Return** (stop waterfall — first success with data wins)
   g. If no fields returned: record as success with empty fieldsWritten, continue to next

Important: The `shouldEnrich` function takes entityId as first param. For companies, use the company's `id` field (not the domain). So first look up the company by domain, get its id, then call shouldEnrich. If company doesn't exist yet, shouldEnrich would return true (no prior enrichment log).

Import everything from the correct local modules. Do NOT import from external packages except `@/lib/db` for prisma.
  </action>
  <verify>
    <automated>cd /Users/jjay/programs/outsignal-agents && npx tsc --noEmit --pretty 2>&1 | head -30</automated>
  </verify>
  <done>enrichEmail and enrichCompany exported from waterfall.ts. enrichEmail tries Prospeo -> LeadMagic -> FindyMail with circuit breaker, retry, cost cap, merge, and normalizers. enrichCompany tries AI Ark -> Firecrawl with same error handling pattern. Both stop at first success.</done>
</task>

<task type="auto">
  <name>Task 2: Update queue for paused status + wire process route + create run trigger</name>
  <files>src/lib/enrichment/queue.ts, src/app/api/enrichment/jobs/process/route.ts, src/app/api/enrichment/run/route.ts, src/lib/enrichment/log.ts</files>
  <action>
**A) Update `src/lib/enrichment/log.ts`** — add optional `workspaceSlug` parameter:

Add `workspaceSlug?: string;` to the `recordEnrichment` params interface. In the prisma.create data, add `workspaceSlug: params.workspaceSlug ?? null`. This connects enrichment logs to workspaces for cost dashboard queries.

**B) Update `src/lib/enrichment/queue.ts`** — handle "paused" status:

1. In `processNextChunk`, update the `findFirst` query to ALSO pick up paused jobs whose `resumeAt` is in the past:
   ```typescript
   const job = await prisma.enrichmentJob.findFirst({
     where: {
       OR: [
         { status: "pending" },
         { status: "paused", resumeAt: { lte: new Date() } },
       ],
     },
     orderBy: { createdAt: "asc" },
   });
   ```

2. Add the `onProcess` callback to handle `DAILY_CAP_HIT` errors specially. In the catch block inside the entity processing loop, check for the `DAILY_CAP_HIT` error message:
   ```typescript
   } catch (err) {
     const errMsg = err instanceof Error ? err.message : String(err);
     if (errMsg === "DAILY_CAP_HIT") {
       // Pause the job — set resumeAt to midnight UTC tomorrow
       const tomorrow = new Date();
       tomorrow.setUTCDate(tomorrow.getUTCDate() + 1);
       tomorrow.setUTCHours(0, 0, 0, 0);
       await prisma.enrichmentJob.update({
         where: { id: job.id },
         data: {
           status: "paused",
           resumeAt: tomorrow,
           processedCount: chunkStart + processedInChunk,
         },
       });
       return { jobId: job.id, processed: processedInChunk, total: job.totalCount, done: false, status: "paused" };
     }
     errors.push({ entityId, error: errMsg });
   }
   ```

   This requires tracking `processedInChunk` — add a counter variable that increments after each successful entity processing in the loop.

3. Update the `EnqueueJobParams` interface to accept `provider` as optional (since waterfall handles provider selection internally, not the job):
   Actually NO — keep provider as-is. The job specifies which waterfall to run (person → email waterfall, company → company waterfall). The `provider` field on EnrichmentJob is less relevant now since the waterfall tries multiple providers, but keep it for backwards compatibility. When queuing a waterfall job, use `provider: "prospeo"` as a convention to mean "email waterfall" (first provider). Actually, better: make provider optional in EnqueueJobParams and default to "prospeo" for person jobs and "aiark" for company jobs.

   Scratch that — keep it simple. The `provider` field stays as-is. When the waterfall runs, it tries all providers regardless of what `provider` is set to on the job. The job's `provider` field is just metadata. Don't overcomplicate this.

**C) Update `src/app/api/enrichment/jobs/process/route.ts`** — wire waterfall:

Replace the current no-op call with a wired version:

```typescript
import { NextResponse } from "next/server";
import { processNextChunk } from "@/lib/enrichment/queue";
import { enrichEmail, enrichCompany, createCircuitBreaker } from "@/lib/enrichment/waterfall";
import { prisma } from "@/lib/db";

export async function POST() {
  try {
    // Fresh circuit breaker per invocation (in-memory, resets each batch run)
    const breaker = createCircuitBreaker();

    const result = await processNextChunk(async (entityId, job) => {
      if (job.entityType === "person") {
        const person = await prisma.person.findUniqueOrThrow({ where: { id: entityId } });
        await enrichEmail(
          entityId,
          {
            linkedinUrl: person.linkedinUrl ?? undefined,
            firstName: person.firstName ?? undefined,
            lastName: person.lastName ?? undefined,
            companyName: person.company ?? undefined,
            companyDomain: person.companyDomain ?? undefined,
          },
          breaker,
          job.workspaceSlug ?? undefined,
        );
      } else if (job.entityType === "company") {
        await enrichCompany(entityId, breaker, job.workspaceSlug ?? undefined);
      }
    });

    if (!result) {
      return NextResponse.json({ message: "no pending jobs" });
    }
    return NextResponse.json(result);
  } catch (error) {
    console.error("Job processing error:", error);
    return NextResponse.json(
      { error: error instanceof Error ? error.message : "Job processing failed" },
      { status: 500 },
    );
  }
}
```

Note on enrichCompany: it takes `domain` as first arg, but the entityId from the job is a company ID. The route needs to look up the company to get the domain:
```typescript
} else if (job.entityType === "company") {
  const company = await prisma.company.findUniqueOrThrow({ where: { id: entityId } });
  await enrichCompany(company.domain, breaker, job.workspaceSlug ?? undefined);
}
```

Wait — waterfall.ts's enrichCompany takes domain. But the process route has entityId (company ID). Update: the process route looks up the company by ID and passes domain to enrichCompany. Also need to pass the job metadata (workspaceSlug) — update processNextChunk callback to include workspaceSlug. Actually, the current callback signature is `(entityId, job: { entityType, provider })`. Extend the job object to include `workspaceSlug`:

In queue.ts, update the onProcess callback type to:
```typescript
onProcess?: (entityId: string, job: { entityType: string; provider: string; workspaceSlug?: string | null }) => Promise<void>
```
And pass `workspaceSlug: job.workspaceSlug` in the callback invocation.

**D) Create `src/app/api/enrichment/run/route.ts`** — POST trigger to enqueue batch jobs:

```typescript
import { NextResponse, NextRequest } from "next/server";
import { prisma } from "@/lib/db";
import { enqueueJob } from "@/lib/enrichment/queue";

/**
 * POST /api/enrichment/run
 *
 * Enqueue a batch enrichment job.
 * Body: { entityType: "person" | "company", workspaceSlug?: string, limit?: number }
 *
 * For "person": finds people without email, queues them for email waterfall.
 * For "company": finds companies without industry/headcount, queues for company waterfall.
 */
export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { entityType, workspaceSlug, limit = 100 } = body;

    if (!entityType || !["person", "company"].includes(entityType)) {
      return NextResponse.json({ error: "entityType must be 'person' or 'company'" }, { status: 400 });
    }

    let entityIds: string[];

    if (entityType === "person") {
      // Find people without email who have a LinkedIn URL or name+company
      const people = await prisma.person.findMany({
        where: {
          email: null,
          OR: [
            { linkedinUrl: { not: null } },
            { AND: [{ firstName: { not: null } }, { company: { not: null } }] },
          ],
          ...(workspaceSlug ? { workspaces: { some: { workspace: workspaceSlug } } } : {}),
        },
        select: { id: true },
        take: limit,
      });
      entityIds = people.map((p) => p.id);
    } else {
      // Find companies missing key data
      const companies = await prisma.company.findMany({
        where: {
          OR: [
            { industry: null },
            { headcount: null },
            { description: null },
          ],
        },
        select: { id: true },
        take: limit,
      });
      entityIds = companies.map((c) => c.id);
    }

    if (entityIds.length === 0) {
      return NextResponse.json({ message: "No eligible records found", count: 0 });
    }

    const jobId = await enqueueJob({
      entityType,
      provider: entityType === "person" ? "prospeo" : "aiark", // Convention: first provider in waterfall
      entityIds,
      workspaceSlug,
    });

    return NextResponse.json({ jobId, count: entityIds.length });
  } catch (error) {
    console.error("Enrichment run error:", error);
    return NextResponse.json(
      { error: error instanceof Error ? error.message : "Failed to enqueue enrichment job" },
      { status: 500 },
    );
  }
}
```
  </action>
  <verify>
    <automated>cd /Users/jjay/programs/outsignal-agents && npx tsc --noEmit --pretty 2>&1 | head -30</automated>
  </verify>
  <done>Queue handles paused jobs with resumeAt. Process route wires waterfall via onProcess callback with fresh circuit breaker per invocation. Run route accepts POST with entityType and workspaceSlug, finds eligible records, enqueues job. DAILY_CAP_HIT pauses jobs until midnight UTC tomorrow.</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` — all files compile without errors
2. waterfall.ts exports `enrichEmail`, `enrichCompany`, `createCircuitBreaker`
3. enrichEmail tries providers in order: Prospeo -> LeadMagic -> FindyMail
4. enrichCompany tries providers in order: AI Ark -> Firecrawl
5. Circuit breaker threshold is 5 consecutive failures
6. Exponential backoff on 429: 1s, 2s, 4s
7. DAILY_CAP_HIT pauses job with resumeAt = midnight UTC tomorrow
8. Queue picks up both "pending" and "paused with expired resumeAt" jobs
9. Normalizers (classifyIndustry, classifyJobTitle, classifyCompanyName) called after writes
10. Process route creates fresh circuit breaker per invocation
11. Run route finds eligible records and enqueues job
12. recordEnrichment accepts workspaceSlug parameter
</verification>

<success_criteria>
- Email waterfall executes Prospeo -> LeadMagic -> FindyMail in order, stopping at first email found
- Company waterfall executes AI Ark -> Firecrawl, stopping at first success
- Cost cap pauses jobs gracefully and resumes next day
- Circuit breaker prevents hammering a failing provider
- Normalizers fire inline after data writes
- Everything is wired end-to-end: run trigger -> job queue -> process route -> waterfall -> providers -> merge -> normalize
</success_criteria>

<output>
After completion, create `.planning/phases/02-provider-adapters-waterfall/02-04-SUMMARY.md`
</output>
